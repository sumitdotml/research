{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2fc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7867388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "seqlen = 3\n",
    "d_model = 32\n",
    "d_head = 8\n",
    "assert d_model % d_head == 0\n",
    "heads = d_model // d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73bdacde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32]),\n",
       " tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
       "           -1.6047, -0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594,\n",
       "           -0.7688,  0.7624,  1.6423, -0.1596, -0.4974,  0.4396, -0.7581,\n",
       "            1.0783,  0.8008,  1.6806,  1.2791,  1.2964,  0.6105,  1.3347,\n",
       "           -0.2316,  0.0418, -0.2516,  0.8599],\n",
       "          [-1.3847, -0.8712, -0.2234,  1.7174,  0.3189, -0.4245,  0.3057,\n",
       "           -0.7746, -1.5576,  0.9956, -0.8798, -0.6011, -1.2742,  2.1228,\n",
       "           -1.2347, -0.4879, -0.9138, -0.6581,  0.0780,  0.5258, -0.4880,\n",
       "            1.1914, -0.8140, -0.7360, -1.4032,  0.0360, -0.0635,  0.6756,\n",
       "           -0.0978,  1.8446, -1.1845,  1.3835],\n",
       "          [ 1.4451,  0.8564,  2.2181,  0.5232,  0.3466, -0.1973, -1.0546,\n",
       "            1.2780, -0.1722,  0.5238,  0.0566,  0.4263,  0.5750, -0.6417,\n",
       "           -2.2064, -0.7508,  0.0109, -0.3387, -1.3407, -0.5854,  0.5362,\n",
       "            0.5246,  1.1412,  0.0516,  0.7440, -0.4816, -1.0495,  0.6039,\n",
       "           -1.7223, -0.8278,  1.3347,  0.4835]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.randn(batch, seqlen, d_model)\n",
    "W_Q = torch.randn(d_model, d_model)\n",
    "W_K = torch.randn(d_model, d_model)\n",
    "W_V = torch.randn(d_model, d_model)\n",
    "W_O = torch.randn(d_model, d_model)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99ec3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 3, 8]), torch.Size([1, 4, 3, 8]), torch.Size([1, 4, 3, 8]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (x.__matmul__(W_Q)).view(batch, seqlen, heads, d_head).transpose(1, 2)\n",
    "k = (x.__matmul__(W_K)).view(batch, seqlen, heads, d_head).transpose(1, 2)\n",
    "v = (x.__matmul__(W_V)).view(batch, seqlen, heads, d_head).transpose(1, 2)\n",
    "\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0529ea2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = q.__matmul__(torch.transpose(k, -2, -1))\n",
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3c15ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores / d_head ** 0.5, dim=-1)\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795d1aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attended_vals = attn_weights.__matmul__(v)\n",
    "attended_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7da1ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_heads_combined = attended_vals.transpose(1, 2).contiguous().view(batch, seqlen, d_model)\n",
    "output_heads_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e777c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_proj = output_heads_combined.__matmul__(W_O)\n",
    "output_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84232451",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1e4d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_QK = W_Q.__matmul__(torch.transpose(W_K, 0, 1))\n",
    "W_QK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cedbf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_OV = W_V.__matmul__(W_O)\n",
    "W_OV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152b6807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1637, -1.2390, -1.0557,  ..., -0.3666, -1.3768, -0.6575],\n",
       "        [ 1.8197, -0.5205,  1.4799,  ...,  0.0713, -0.8059, -0.3507],\n",
       "        [ 1.1280,  0.0259, -0.1495,  ...,  0.7496, -1.2053,  1.4265]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 512)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a943151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_ = a.__matmul__(torch.randn(512, 64))\n",
    "Q_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f4629",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6811cba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3367,    -inf,    -inf],\n",
       "         [ 0.2303, -1.1229,    -inf],\n",
       "         [ 2.2082, -0.6380,  0.4617]]),\n",
       " tensor([[ 0.3367,  0.1288,  0.2345],\n",
       "         [ 0.2303, -1.1229, -0.1863],\n",
       "         [ 2.2082, -0.6380,  0.4617]]),\n",
       " tensor([[1.0000, 0.0000, 0.0000],\n",
       "         [0.6630, 0.3370, 0.0000],\n",
       "         [0.6029, 0.1453, 0.2518]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some sample stuff\n",
    "torch.manual_seed(42)\n",
    "attn_scores = torch.randn(3, 3)\n",
    "d_hidden = 8 # aka d_model\n",
    "q_last_layer = 4\n",
    "\n",
    "\n",
    "upper_triangular = torch.triu(torch.ones_like(attn_scores), 1)\n",
    "mask_bool = upper_triangular.bool()[:, :]\n",
    "attn_scores_w_causal_mask = torch.masked_fill(attn_scores, mask_bool, value=torch.tensor(float(\"-inf\")))\n",
    "attn_w = torch.softmax(attn_scores_w_causal_mask / q_last_layer ** 0.5, -1)\n",
    "attn_scores_w_causal_mask, attn_scores, attn_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05487f03",
   "metadata": {},
   "source": [
    "The following are assumed to be the attention scores, attention scores (with masking), and attention weights for the input \"The cat sat\".\n",
    "\n",
    "```python\n",
    "(tensor([[ 0.3367,    -inf,    -inf],\n",
    "         [ 0.2303, -1.1229,    -inf],\n",
    "         [ 2.2082, -0.6380,  0.4617]]),\n",
    "\n",
    " tensor([[ 0.3367,  0.1288,  0.2345],\n",
    "         [ 0.2303, -1.1229, -0.1863],\n",
    "         [ 2.2082, -0.6380,  0.4617]]),\n",
    "         \n",
    " tensor([[1.0000, 0.0000, 0.0000],\n",
    "         [0.6630, 0.3370, 0.0000],\n",
    "         [0.6029, 0.1453, 0.2518]]))\n",
    "```\n",
    "\n",
    "\n",
    "Looking at the 3x3 attention weights matrix, I can picture this as:\n",
    "\n",
    "|       | The   |  cat  | sat |\n",
    "|-------|-------|-------|-------|\n",
    "| The   | 1.0000 | 0.0000 | 0.0000 |\n",
    "| cat   | 0.6630 | 0.3370 | 0.0000 |\n",
    "| sat   | 0.6029 | 0.1453 | 0.2518 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0498689",
   "metadata": {},
   "source": [
    "Here, I can think of it like this:\n",
    "\n",
    "1. to understand \"cat\", how much will I have to look at the token \"the\"? --> exactly 1.000, so strong relevance for this computation.\n",
    "2. to understand \"sat\", how much will I have to look at the token \"the\"? --> 0.6029, so a pretty solid relevance for this computation.\n",
    "3. to understand \"sat\", how much will I have to look at the token \"cat\"? --> 0.1453, so an okay-ish relevance, not as strong as the one just before\n",
    "\n",
    "### Now, attended values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c749e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_V: torch.Size([8, 8])\n",
      "tensor([[ 0.0349,  0.3211,  1.5736, -0.8455,  1.3123,  0.6872, -1.0892, -0.3553],\n",
      "        [-1.4181,  0.8963,  0.0499,  2.2667,  1.1790, -0.4345, -1.3864, -1.2862],\n",
      "        [-0.8371, -0.9224,  1.8113,  0.1606,  0.3672,  0.1754,  1.3852, -0.4459],\n",
      "        [-1.2024,  0.7078, -1.0759,  0.5357,  1.1754,  0.5612, -0.4527, -0.7718],\n",
      "        [ 0.1453,  0.2311,  0.0087, -0.1423,  0.1971, -1.1441,  0.3383,  1.6992],\n",
      "        [ 2.8140,  0.3598, -0.0898,  0.4584, -0.5644,  1.0563, -1.4692,  1.4332],\n",
      "        [ 0.7281, -0.7106, -0.6021,  0.9604,  0.4048, -1.3543, -0.4976,  0.4747],\n",
      "        [-0.1976,  1.2683,  1.2243,  0.0981,  1.7423, -1.3527,  0.2191,  0.5526]])\n",
      "\n",
      "V: torch.Size([3, 8])\n",
      "tensor([[-3.3538, -2.6614,  5.1813, -0.1024,  0.1555, -0.1970, -0.2466, -2.8980],\n",
      "        [-0.4393,  1.2727,  0.4840, -3.8536, -1.8261,  5.3907,  0.3668, -2.1857],\n",
      "        [-0.3070, -0.7861,  2.5214, -1.5471, -1.1485,  1.0364,  2.6574, -0.5662]])\n",
      "\n",
      "attended weights: torch.Size([3, 8])\n",
      "tensor([[-3.3538, -2.6614,  5.1813, -0.1024,  0.1555, -0.1970, -0.2466, -2.8980],\n",
      "        [-2.3715, -1.3356,  3.5982, -1.3666, -0.5123,  1.6862, -0.0399, -2.6579],\n",
      "        [-2.1632, -1.6177,  3.8292, -1.0111, -0.4607,  0.9254,  0.5737, -2.2074]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# assuming:\n",
    "X_IN = torch.randn(3, d_hidden) # [seqlen, d_hidden]\n",
    "W_V_ = torch.randn(d_hidden, d_hidden)\n",
    "V = X_IN.__matmul__(W_V_)\n",
    "W_O_ = torch.randn(d_hidden, d_hidden)\n",
    "\n",
    "ATTENDED = attn_w.__matmul__(V)\n",
    "\n",
    "print(f\"\"\"W_V: {W_V_.shape}\n",
    "{W_V_}\n",
    "\n",
    "V: {V.shape}\n",
    "{V}\n",
    "\n",
    "attended weights: {ATTENDED.shape}\n",
    "{ATTENDED}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3e3b5",
   "metadata": {},
   "source": [
    "### Now the output projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93fea28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8])\n",
      "tensor([[ 10.8347,  -4.9027,   7.4389,  -2.5553,   9.3776,  -2.1711, -14.9518,\n",
      "          -5.0850],\n",
      "        [  8.7450,  -3.9095,   3.6260,  -2.4063,   5.4063,  -1.0348, -11.8651,\n",
      "          -2.1552],\n",
      "        [  9.2331,  -4.1688,   2.8769,  -2.0400,   4.9977,  -1.7839, -11.5206,\n",
      "          -2.4551]])\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PROJECTION = ATTENDED.__matmul__(W_O_)\n",
    "print(f\"\"\"{OUTPUT_PROJECTION.shape}\n",
    "{OUTPUT_PROJECTION}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38303f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 8]),\n",
       " tensor([[ 12.7616,  -3.4154,   8.3396,  -4.6608,  10.0561,  -3.4056, -14.9948,\n",
       "           -6.6897],\n",
       "         [  9.1009,  -4.5961,   3.1327,  -2.1649,   4.2954,  -0.9433, -14.1820,\n",
       "           -2.3720],\n",
       "         [  8.9234,  -4.5645,   3.6803,  -2.6616,   4.4057,  -1.8470, -12.3491,\n",
       "           -2.1242]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_stream = X_IN + OUTPUT_PROJECTION\n",
    "# this is bascially:\n",
    "#   x_in + attended_val @ W_O                  (here, x_in = (enbeddings + pos_encodings), and attended_val @ W_O = output_projection)\n",
    "# = x_in + (attention_weights @ V) @ W_O\n",
    "\n",
    "\n",
    "\n",
    "# = x_in + ((Q @ K.T) @ (x_in @ W_V) @ W_O)    (simplifying the attn weights a little here, softmax and being divide by d_k ** 0.5 are omitted)\n",
    "residual_stream.shape, residual_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53246b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8.9234,  -4.5645,   3.6803,  -2.6616,   4.4057,  -1.8470, -12.3491,\n",
       "         -2.1242])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for, say, the word \"sat\" (3rd word in the sequence):\n",
    "W_sat = residual_stream[2]\n",
    "\n",
    "# this is:\n",
    "#   residual[\"sat\"] aka residual[2]\n",
    "# = x_in[\"sat\"] + attended_val[\"sat\"] @ W_O\n",
    "# \n",
    "# Let's assume our attention weight matrix was:\n",
    "#      The     cat    sat\n",
    "# The  1.00     0      0\n",
    "# cat  0.74    0.26    0\n",
    "# sat  0.20    0.50    0.30\n",
    "\n",
    "# this means attention_weights[\"sat\"] = [0,20, 0.50, 0.30]\n",
    "\n",
    "# so, residual[\"sat\"]:\n",
    "# = x_in[\"sat\"] + attended_val[\"sat\"]                           @ W_O\n",
    "# = x_in[\"sat\"] + (attention_weights[\"sat\"] @ V)                @ W_O\n",
    "# = x_in[\"sat\"] + ([0.2, 0.5, 0.3] @ [V_The, V_cat, V_sat])     @ W_O\n",
    "# = x_in[\"sat\"] + (0.2 * V_The + 0.5 * V_cat + 0.3 * V_sat)     @ W_O\n",
    "# = x_in[\"sat\"] + (0.2 * x_in[\"the\"] + 0.5 * x_in[\"cat\"] + 0.3 * x_in[\"sat\"]) @ W_O\n",
    "\n",
    "\n",
    "W_sat # x_in[\"sat\"] + (0.2 * x_in[\"the\"] + 0.5 * x_in[\"cat\"] + 0.3 * x_in[\"sat\"]) @ W_O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0cfc1",
   "metadata": {},
   "source": [
    "So basically, we can divide this process into 2 parts:\n",
    "\n",
    "```python\n",
    "# 1. The QK circuit:\n",
    "Q @ K.T\n",
    "= (x @ W_Q) @ (x @ W_K).T\n",
    "\n",
    "# 2. The OV circuit:\n",
    "(attention_weight @ V) @ W_O\n",
    "= (attention_weight @ (x @ W_V) @ W_O)\n",
    "= (attention_weight @ x) @ (W_V @ W_O)\n",
    "```\n",
    "\n",
    "Why talk about `W_OV = W_V @ W_O`? => For analysis and interpretability\n",
    "\n",
    "Instead of thinking \"first we transform by `W_V`, then later by `W_O`,\" we can think: \"This attention head applies a single combined transformation `W_OV` to move information.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
